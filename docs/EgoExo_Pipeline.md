# Using GraVi-T with egoexo

Short project description goes here.

## Table of Contents

- [Setup](#Setup)
- [Run GraVi-T](#GraVi-T)
- [Run MLP](#MLP)


## Setup. If you are setting up a new experiment follow these steps.
1. Copy bundle files to annotations/<dataset-name>/splits. If you need to create new splits please generate .bundle splits here: `python /local/juro4948/data/egoexo4d/generate_splits.py` (this is not in the GraVi-T repo)
2. Run generate_symlinks.ipynb to set up symlinks in /home/juro4948/gravit/GraVi-T/data/features pointing to the npy features. All samples in the train/validation groups should be placed in the corresponding split folder. The bundle files will inform the program which samples are in train vs. validation.
3. Check the config files to make sure the filepaths are to the correct data and annotations files.

File structure:
- Annotations need to be saved at data/annotations/<dataset_name>/groundTruth/<unique_name>.txt
- Splits need to be saved at data/annotations/<dataset_name>/splits/<test(train)>.split<n>.bundle
- Class Int: String mapping needs to be saved at data/annotations/<dataset_name>/mapping.txt
*Where <dataset_name> is specified in the correct config yaml file.*
- Features need to be saved at data/features/<features_name>/split<n>/<train(val)>/<unique_name>.npy where features_name is specified by the flag input to generate_temporal_graphs script.
*The lengths of the feature file and corresponding annotations file need to align. Can align with downsampling/etc in generate_temporal_graphs code.*



## Run GraVi-T (Only ready for omnivore)
1. Generate the Pytorch-geometric graphs: 
    -   For aria single-view: `python data/generate_temporal_graphs.py --features egoexo-omnivore-aria --tauf 10 --dataset egoexo-omnivore-aria` where the dataset name points to the annotations dir
    - For GoPro:
        -    Multi-view: `python data/generate_temporal_graphs.py --features egoexo-omnivore-gopro --tauf 10 --dataset egoexo-omnivore-aria --is_multiview True`
    - At the moment, the code for egoexo-omnivore assumes that both the features and labels are at 30FPS. All EgoExo Omnivore features are at 30 FPS (even the GoPro streams) but the labels are generated by the preprocess.ipynb notebook. Currently I have it set to 30 FPS but if you are unsure then double check. 
    - The raw EgoExo GoPro data is at 60FPS, while the raw Aria data is at 30FPS.
2. Train model. `python tools/train_context_reasoning.py --cfg configs/action-segmentation/egoexo-omnivore/SPELL_default.yaml --split 2`
3. Evaluate: ``

## Run MLP: 1st-person (Aria) features
1. Config file must contain these: 
For Omnivore Features, modify this config: configs/action-segmentation/egoexo-omnivore/MLP_default.yaml
    - graph_name: mlp
    - input_dim: 1536
    - dataset: egoexo-omnivore-aria
    - model_name: SimpleMLP
For Bridge-Prompt Features, modify this config: configs/action-segmentation/egoexo/MLP_default.yaml
    - graph_name: mlp
    - input_dim: 756 # dimension of the Bridge Prompt features
    - dataset: egoexo-aria-brp
    - model_name: SimpleMLP
2. Train: 
For Omnivore Features: `python tools/train_naive.py --cfg configs/action-segmentation/egoexo-omnivore/MLP_default.yaml --split 1`
For Bridge-Prompt Features: `python tools/train_naive.py --cfg configs/action-segmentation/egoexo/MLP_default.yaml --split 1`
3. Evaluate: 
Omnivore: `python tools/evaluate_naive.py --dataset egoexo-omnivore-aria --exp_name <name your experiment> --eval_type AS`
Bridge-Prompt: `python tools/evaluate_naive.py --dataset egoexo-aria-brp --exp_name <name your experiment> --eval_type AS`
where <name your experiment> will be created and is the output directory in results/ where this experiment's results are stored.
